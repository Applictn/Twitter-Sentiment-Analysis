{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Keyword/Tag to search about: narendra modi\n",
      "Enter how many tweets to search: 200\n",
      "How people are reacting on narendra modi by analyzing 200 tweets.\n",
      "\n",
      "General Report: \n",
      "Weakly Positive\n",
      "\n",
      "Detailed Report: \n",
      "18.00% people thought it was positive\n",
      "39.50% people thought it was weakly positive\n",
      "6.00% people thought it was strongly positive\n",
      "1.00% people thought it was negative\n",
      "1.50% people thought it was weakly negative\n",
      "0.00% people thought it was strongly negative\n",
      "34.00% people thought it was neutral\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys,tweepy,csv,re\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class SentimentAnalysis:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tweets = []\n",
    "        self.tweetText = []\n",
    "\n",
    "    def DownloadData(self):\n",
    "        # authenticating\n",
    "        consumerKey = 'O2lJdKPfcfXZSyFJRmPFyy2co'\n",
    "        consumerSecret = 'qXDH3TN1Qb1NuOy3cgSXjO7W3t5Bvesbv8DuiOEFjVXHrMA1fb'\n",
    "        accessToken = '451266139-cGBI3dKvXH0en6hHBk3nEVdU27y0TCnhEWEcJAsz'\n",
    "        accessTokenSecret = 'sRloOTkeB2CaAFNvEkhgO69OD1XH6qnCcCkZxa24BXZTM'\n",
    "        auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "        auth.set_access_token(accessToken, accessTokenSecret)\n",
    "        api = tweepy.API(auth)\n",
    "\n",
    "        # input for term to be searched and how many tweets to search\n",
    "        searchTerm = input(\"Enter Keyword/Tag to search about: \")\n",
    "        NoOfTerms = int(input(\"Enter how many tweets to search: \"))\n",
    "\n",
    "        # searching for tweets\n",
    "        self.tweets = tweepy.Cursor(api.search, q=searchTerm, lang = \"en\").items(NoOfTerms)\n",
    "\n",
    "        # Open/create a file to append data to\n",
    "        csvFile = open('result.csv', 'a')\n",
    "\n",
    "        # Use csv writer\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "\n",
    "\n",
    "        # creating some variables to store info\n",
    "        polarity = 0\n",
    "        positive = 0\n",
    "        wpositive = 0\n",
    "        spositive = 0\n",
    "        negative = 0\n",
    "        wnegative = 0\n",
    "        snegative = 0\n",
    "        neutral = 0\n",
    "\n",
    "\n",
    "        # iterating through tweets fetched\n",
    "        for tweet in self.tweets:\n",
    "            #Append to temp so that we can store in csv later. I use encode UTF-8\n",
    "            self.tweetText.append(self.cleanTweet(tweet.text).encode('utf-8'))\n",
    "            # print (tweet.text.translate(non_bmp_map))    #print tweet's text\n",
    "            analysis = TextBlob(tweet.text)\n",
    "            # print(analysis.sentiment)  # print tweet's polarity\n",
    "            polarity += analysis.sentiment.polarity  # adding up polarities to find the average later\n",
    "\n",
    "            if (analysis.sentiment.polarity == 0):  # adding reaction of how people are reacting to find average later\n",
    "                neutral += 1\n",
    "            elif (analysis.sentiment.polarity > 0 and analysis.sentiment.polarity <= 0.3):\n",
    "                wpositive += 1\n",
    "            elif (analysis.sentiment.polarity > 0.3 and analysis.sentiment.polarity <= 0.6):\n",
    "                positive += 1\n",
    "            elif (analysis.sentiment.polarity > 0.6 and analysis.sentiment.polarity <= 1):\n",
    "                spositive += 1\n",
    "            elif (analysis.sentiment.polarity > -0.3 and analysis.sentiment.polarity <= 0):\n",
    "                wnegative += 1\n",
    "            elif (analysis.sentiment.polarity > -0.6 and analysis.sentiment.polarity <= -0.3):\n",
    "                negative += 1\n",
    "            elif (analysis.sentiment.polarity > -1 and analysis.sentiment.polarity <= -0.6):\n",
    "                snegative += 1\n",
    "\n",
    "\n",
    "        # Write to csv and close csv file\n",
    "        csvWriter.writerow(self.tweetText)\n",
    "        csvFile.close()\n",
    "\n",
    "        # finding average of how people are reacting\n",
    "        positive = self.percentage(positive, NoOfTerms)\n",
    "        wpositive = self.percentage(wpositive, NoOfTerms)\n",
    "        spositive = self.percentage(spositive, NoOfTerms)\n",
    "        negative = self.percentage(negative, NoOfTerms)\n",
    "        wnegative = self.percentage(wnegative, NoOfTerms)\n",
    "        snegative = self.percentage(snegative, NoOfTerms)\n",
    "        neutral = self.percentage(neutral, NoOfTerms)\n",
    "\n",
    "        # finding average reaction\n",
    "        polarity = polarity / NoOfTerms\n",
    "\n",
    "        # printing out data\n",
    "        print(\"How people are reacting on \" + searchTerm + \" by analyzing \" + str(NoOfTerms) + \" tweets.\")\n",
    "        print()\n",
    "        print(\"General Report: \")\n",
    "\n",
    "        if (polarity == 0):\n",
    "            print(\"Neutral\")\n",
    "        elif (polarity > 0 and polarity <= 0.3):\n",
    "            print(\"Weakly Positive\")\n",
    "        elif (polarity > 0.3 and polarity <= 0.6):\n",
    "            print(\"Positive\")\n",
    "        elif (polarity > 0.6 and polarity <= 1):\n",
    "            print(\"Strongly Positive\")\n",
    "        elif (polarity > -0.3 and polarity <= 0):\n",
    "            print(\"Weakly Negative\")\n",
    "        elif (polarity > -0.6 and polarity <= -0.3):\n",
    "            print(\"Negative\")\n",
    "        elif (polarity > -1 and polarity <= -0.6):\n",
    "            print(\"Strongly Negative\")\n",
    "\n",
    "        print()\n",
    "        print(\"Detailed Report: \")\n",
    "        print(str(positive) + \"% people thought it was positive\")\n",
    "        print(str(wpositive) + \"% people thought it was weakly positive\")\n",
    "        print(str(spositive) + \"% people thought it was strongly positive\")\n",
    "        print(str(negative) + \"% people thought it was negative\")\n",
    "        print(str(wnegative) + \"% people thought it was weakly negative\")\n",
    "        print(str(snegative) + \"% people thought it was strongly negative\")\n",
    "        print(str(neutral) + \"% people thought it was neutral\")\n",
    "\n",
    "        self.plotPieChart(positive, wpositive, spositive, negative, wnegative, snegative, neutral, searchTerm, NoOfTerms)\n",
    "\n",
    "\n",
    "    def cleanTweet(self, tweet):\n",
    "        # Remove Links, Special Characters etc from tweet\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) | (\\w +:\\ / \\ / \\S +)\", \" \", tweet).split())\n",
    "\n",
    "    # function to calculate percentage\n",
    "    def percentage(self, part, whole):\n",
    "        temp = 100 * float(part) / float(whole)\n",
    "        return format(temp, '.2f')\n",
    "\n",
    "    def plotPieChart(self, positive, wpositive, spositive, negative, wnegative, snegative, neutral, searchTerm, noOfSearchTerms):\n",
    "        labels = ['Positive [' + str(positive) + '%]', 'Weakly Positive [' + str(wpositive) + '%]','Strongly Positive [' + str(spositive) + '%]', 'Neutral [' + str(neutral) + '%]',\n",
    "                  'Negative [' + str(negative) + '%]', 'Weakly Negative [' + str(wnegative) + '%]', 'Strongly Negative [' + str(snegative) + '%]']\n",
    "        sizes = [positive, wpositive, spositive, neutral, negative, wnegative, snegative]\n",
    "        colors = ['yellowgreen','lightgreen','darkgreen', 'gold', 'red','lightsalmon','darkred']\n",
    "        patches, texts = plt.pie(sizes, colors=colors, startangle=90)\n",
    "        plt.legend(patches, labels, loc=\"best\")\n",
    "        plt.title('How people are reacting on ' + searchTerm + ' by analyzing ' + str(noOfSearchTerms) + ' Tweets.')\n",
    "        plt.axis('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    sa = SentimentAnalysis()\n",
    "    sa.DownloadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tweets                   id  \\\n",
      "0  In New York State, Democrats blocked a Bill ex...  1116911640568573952   \n",
      "1  Another Fake Story on @NBCNews that I offered ...  1116907128445394944   \n",
      "2  A Fake Story by Politico. Made up sources. Tha...  1116898703682543616   \n",
      "3  RT @politicalelle: How is this woman walking t...  1116896641775296513   \n",
      "4  RT @dbongino: With the exception of FISA warra...  1116895132270383104   \n",
      "5  Finally, great news at the Border! https://t.c...  1116894304063107072   \n",
      "6  Thank you Jeh, so well stated! https://t.co/4Q...  1116892526533857280   \n",
      "7  If the Radical Left Democrats all of a sudden ...  1116891452003557376   \n",
      "8  WSJ's Strassel: Barr 'Right' to Say 'Spying' O...  1116845082945171457   \n",
      "9  RT @trish_regan: .@CLewandowski_ says he is PO...  1116833058840293381   \n",
      "\n",
      "   len                date              source  likes  retweets  sentiment  \n",
      "0  140 2019-04-13 03:51:00  Twitter for iPhone  27399      8946          1  \n",
      "1  140 2019-04-13 03:33:05  Twitter for iPhone  29128      8787         -1  \n",
      "2   90 2019-04-13 02:59:36  Twitter for iPhone  21108      6367         -1  \n",
      "3   96 2019-04-13 02:51:24  Twitter for iPhone      0      7020          0  \n",
      "4  144 2019-04-13 02:45:25  Twitter for iPhone      0      6337          0  \n",
      "5   58 2019-04-13 02:42:07  Twitter for iPhone  17731      5136          1  \n",
      "6   54 2019-04-13 02:35:03  Twitter for iPhone  22001      6197          0  \n",
      "7  140 2019-04-13 02:30:47  Twitter for iPhone  50545     15692         -1  \n",
      "8  126 2019-04-12 23:26:32  Twitter for iPhone  34762     10654          1  \n",
      "9  140 2019-04-12 22:38:45  Twitter for iPhone      0      8828          1  \n"
     ]
    }
   ],
   "source": [
    "from tweepy import API \n",
    "from tweepy import Cursor\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "from textblob import TextBlob\n",
    " \n",
    "#import twitter_credentials\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# # # # TWITTER CLIENT # # # #\n",
    "class TwitterClient():\n",
    "    def __init__(self, twitter_user=None):\n",
    "        self.auth = TwitterAuthenticator().authenticate_twitter_app()\n",
    "        self.twitter_client = API(self.auth)\n",
    "\n",
    "        self.twitter_user = twitter_user\n",
    "\n",
    "    def get_twitter_client_api(self):\n",
    "        return self.twitter_client\n",
    "\n",
    "    def get_user_timeline_tweets(self, num_tweets):\n",
    "        tweets = []\n",
    "        for tweet in Cursor(self.twitter_client.user_timeline, id=self.twitter_user).items(num_tweets):\n",
    "            tweets.append(tweet)\n",
    "        return tweets\n",
    "\n",
    "    def get_friend_list(self, num_friends):\n",
    "        friend_list = []\n",
    "        for friend in Cursor(self.twitter_client.friends, id=self.twitter_user).items(num_friends):\n",
    "            friend_list.append(friend)\n",
    "        return friend_list\n",
    "\n",
    "    def get_home_timeline_tweets(self, num_tweets):\n",
    "        home_timeline_tweets = []\n",
    "        for tweet in Cursor(self.twitter_client.home_timeline, id=self.twitter_user).items(num_tweets):\n",
    "            home_timeline_tweets.append(tweet)\n",
    "        return home_timeline_tweets\n",
    "\n",
    "\n",
    "# # # # TWITTER AUTHENTICATER # # # #\n",
    "class TwitterAuthenticator():\n",
    "\n",
    "    def authenticate_twitter_app(self):\n",
    "        consumerKey = 'O2lJdKPfcfXZSyFJRmPFyy2co'\n",
    "        consumerSecret = 'qXDH3TN1Qb1NuOy3cgSXjO7W3t5Bvesbv8DuiOEFjVXHrMA1fb'\n",
    "        accessToken = '451266139-cGBI3dKvXH0en6hHBk3nEVdU27y0TCnhEWEcJAsz'\n",
    "        accessTokenSecret = 'sRloOTkeB2CaAFNvEkhgO69OD1XH6qnCcCkZxa24BXZTM'\n",
    "        auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "        auth.set_access_token(accessToken, accessTokenSecret)\n",
    "        return auth\n",
    "\n",
    "# # # # TWITTER STREAMER # # # #\n",
    "class TwitterStreamer():\n",
    "    \"\"\"\n",
    "    Class for streaming and processing live tweets.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.twitter_autenticator = TwitterAuthenticator()    \n",
    "\n",
    "    def stream_tweets(self, fetched_tweets_filename, hash_tag_list):\n",
    "        # This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "        listener = TwitterListener(fetched_tweets_filename)\n",
    "        auth = self.twitter_autenticator.authenticate_twitter_app() \n",
    "        stream = Stream(auth, listener)\n",
    "\n",
    "        # This line filter Twitter Streams to capture data by the keywords: \n",
    "        stream.filter(track=hash_tag_list)\n",
    "\n",
    "\n",
    "# # # # TWITTER STREAM LISTENER # # # #\n",
    "class TwitterListener(StreamListener):\n",
    "    \"\"\"\n",
    "    This is a basic listener that just prints received tweets to stdout.\n",
    "    \"\"\"\n",
    "    def __init__(self, fetched_tweets_filename):\n",
    "        self.fetched_tweets_filename = fetched_tweets_filename\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            print(data)\n",
    "            with open(self.fetched_tweets_filename, 'a') as tf:\n",
    "                tf.write(data)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data %s\" % str(e))\n",
    "        return True\n",
    "          \n",
    "    def on_error(self, status):\n",
    "        if status == 420:\n",
    "            # Returning False on_data method in case rate limit occurs.\n",
    "            return False\n",
    "        print(status)\n",
    "\n",
    "\n",
    "class TweetAnalyzer():\n",
    "    \"\"\"\n",
    "    Functionality for analyzing and categorizing content from tweets.\n",
    "    \"\"\"\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "    def analyze_sentiment(self, tweet):\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        \n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 1\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def tweets_to_data_frame(self, tweets):\n",
    "        df = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['tweets'])\n",
    "\n",
    "        df['id'] = np.array([tweet.id for tweet in tweets])\n",
    "        df['len'] = np.array([len(tweet.text) for tweet in tweets])\n",
    "        df['date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "        df['source'] = np.array([tweet.source for tweet in tweets])\n",
    "        df['likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "        df['retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "\n",
    "        return df\n",
    "\n",
    " \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    twitter_client = TwitterClient()\n",
    "    tweet_analyzer = TweetAnalyzer()\n",
    "\n",
    "    api = twitter_client.get_twitter_client_api()\n",
    "\n",
    "    tweets = api.user_timeline(screen_name=\"realDonaldTrump\", count=200)\n",
    "\n",
    "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
    "    df['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df['tweets']])\n",
    "\n",
    "    print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
